{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Certificate in Data Science | Milestone 2 |  \n",
    "> University of Washington, Seattle, WA    \n",
    "> January 2020  \n",
    "> N. Hicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Milestone 2 continues your work with the diaper manufacturing problem, using the same datasets:\n",
    "- A dataset file SECOM containing 1567 examples, each with 591 features, presented in a 1567 x 591 matrix.\n",
    "- A labels file listing the classifications and date time stamp for each example.\n",
    "\n",
    "Accomplish the following outcomes:\n",
    "    - Split prepared data from Milestone 1 into training and testing data.\n",
    "    - Build a decision tree model that detects faulty products.\n",
    "    - Build an ensemble model that detects faulty products.\n",
    "    - Build an SVM model that detects faulty products.\n",
    "    - Evaluate all three models.\n",
    "    - Solicit specific feedback on your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Existing Work\n",
    "As derived in previously accomplished assignment `Milestone 01`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish the Datatset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:24.784117Z",
     "start_time": "2019-12-29T04:20:21.532931Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NateDogg\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\NateDogg\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\NateDogg\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\NateDogg\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\NateDogg\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\NateDogg\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Import Required Libraries\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Scripting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:24.806119Z",
     "start_time": "2019-12-29T04:20:24.794118Z"
    },
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Retrieve the prescribed dataset.\n",
    "RETURN: pd.DataFrame\n",
    "'''\n",
    "def fetch_data(path, file):\n",
    "    try:\n",
    "        # import the file to a dataframe\n",
    "        _df = pd.read_csv(path + file, sep=' ', header=None)\n",
    "        print('REMOTE FILE USED')\n",
    "    except:\n",
    "        # Local Copy -- Link would not permit access\n",
    "        path = os.getcwd()\n",
    "        print('LOCAL FILE USED\\n\\n')\n",
    "        # import the file to a dataframe\n",
    "        _df = pd.read_csv(os.path.join(path, file))\n",
    "    \n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:24.831120Z",
     "start_time": "2019-12-29T04:20:24.812119Z"
    },
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create a scale function for a single feature.\n",
    "RETURN: a scaled column feature\n",
    "'''\n",
    "def scale(col):\n",
    "    mean_col = np.mean(col)\n",
    "    sd_col = np.std(col)\n",
    "    std = (col - mean_col) / sd_col\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:25.089135Z",
     "start_time": "2019-12-29T04:20:25.074134Z"
    },
    "code_folding": [
     9
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Accomplish a 'train-test-validate' split of a provided dataset.\n",
    "INPUT: pd.DataFrame\n",
    "RETURN: pd.DataFrame| [train, validate, test]\n",
    "'''\n",
    "    # np.split will split at 60% of the length of the shuffled array,\n",
    "    # then 80% of length (which is an additional 20% of data),\n",
    "    # thus leaving a remaining 20% of the data.\n",
    "    # This is due to the definition of the function.\n",
    "def train_test_validate_split(_df):\n",
    "    train, validate, test = np.split(_df.sample(frac=1), [int(.6*len(_df)), int(.8*len(_df))])\n",
    "    print('TRAIN:    {}\\nVALIDATE: {}\\nTEST:     {}'.format(train.shape, validate.shape, test.shape))\n",
    "    return [train, validate, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:26.295183Z",
     "start_time": "2019-12-29T04:20:26.288183Z"
    },
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generate an accuracy Score for a Decision Tree\n",
    "INPUT: y_test|the test target, y_pred|the predicted scores\n",
    "RETURN: prints the Accuracy Score\n",
    "'''\n",
    "def print_scores_decision_tree(y_test, y_pred):\n",
    "    print('Accuracy: {}%'.format(np.round(accuracy_score(y_test, y_pred)*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:26.874216Z",
     "start_time": "2019-12-29T04:20:26.864216Z"
    },
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Establish an appropriately labeled confusion matrix  \n",
    "INPUT: y_test|test target, y_pred| test prediction, pos|positivie outcome, neg|negative outcome\n",
    "RETURN: pd.DataFrame\n",
    "'''\n",
    "def conf_matrix(y_test, y_pred, pos, neg):\n",
    "    return pd.DataFrame(\n",
    "        confusion_matrix(y_test, y_pred),\n",
    "        columns=['Predicted '+neg, 'Predicted '+pos],\n",
    "        index=['True '+neg, 'True '+pos]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:27.558255Z",
     "start_time": "2019-12-29T04:20:27.543255Z"
    },
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Derive the accuracy score for the Random Forest Decision Tree,\n",
    "Derive the accuracy score for the Gradient Descent Boost Decision Tree\n",
    "RETURN: print of the accuracy score\n",
    "'''\n",
    "def print_scores_ensemble_tree(model, X, y):\n",
    "    Y_hat = model.predict(X)\n",
    "    Accuracy = [1 for i in range(len(Y_hat)) if y.iloc[i] == Y_hat[i]]\n",
    "    Accuracy = round(float(np.sum(Accuracy))/len(Y_hat)*100,2)\n",
    "    print('%.2f%%'%Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:33.843543Z",
     "start_time": "2019-12-29T04:20:29.860320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE FILE USED\n",
      "REMOTE FILE USED\n"
     ]
    }
   ],
   "source": [
    "# import the sensors dataset\n",
    "path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/secom/'\n",
    "file_data = 'secom.data'\n",
    "file_labels = 'secom_labels.data'\n",
    "secom_df = fetch_data(path, file_data)\n",
    "labels_df = fetch_data(path, file_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:33.871545Z",
     "start_time": "2019-12-29T04:20:33.856544Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace the 'NaN' values\n",
    "secom_df  = secom_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:33.907547Z",
     "start_time": "2019-12-29T04:20:33.877545Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace all '-1' values with '0' values\n",
    "# this is a more standardized manner with which to display the target attribute\n",
    "labels_df = labels_df.replace(-1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:35.117616Z",
     "start_time": "2019-12-29T04:20:33.916547Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change the dtype of 'labels_df[1]' to datetime\n",
    "cols = [1]\n",
    "labels_df[cols] = labels_df[cols].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:35.210621Z",
     "start_time": "2019-12-29T04:20:35.139617Z"
    }
   },
   "outputs": [],
   "source": [
    "df = secom_df.copy(deep=True)\n",
    "last_col = len(df.columns)\n",
    "labels_df = labels_df.rename(columns={0:last_col, 1:last_col+1})\n",
    "labels_df.columns\n",
    "df = pd.concat([df, labels_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify 'Mean Zero' Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:36.481694Z",
     "start_time": "2019-12-29T04:20:35.542640Z"
    }
   },
   "outputs": [],
   "source": [
    "# return the mean-zero attributes\n",
    "drop_cols = []\n",
    "is_zero = np.mean(df)==0\n",
    "for item in is_zero.index:\n",
    "    if is_zero[item]==True:\n",
    "        drop_cols.append(item)\n",
    "\n",
    "# drop the mean-zero attributes from the DataFrame\n",
    "df = df.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:41.417976Z",
     "start_time": "2019-12-29T04:20:36.498695Z"
    }
   },
   "outputs": [],
   "source": [
    "#re-name the columns, after the dropped attributes\n",
    "new_cols = np.arange(0,len(df.columns))\n",
    "i = 0\n",
    "\n",
    "# rename the attributes, consecutively\n",
    "for item in df.columns:\n",
    "    df.rename(columns={item:new_cols[i]}, inplace=True)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:41.437977Z",
     "start_time": "2019-12-29T04:20:41.425977Z"
    }
   },
   "outputs": [],
   "source": [
    "# define a list of attributes to iterate \n",
    "drop_cols = [478, 479]\n",
    "attributes = df.columns\n",
    "attributes = np.delete(attributes, drop_cols)\n",
    "target = drop_cols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:41.471979Z",
     "start_time": "2019-12-29T04:20:41.447978Z"
    }
   },
   "outputs": [],
   "source": [
    "# establish the attributes and target\n",
    "X = df.copy()\n",
    "X = X.drop(drop_cols, axis=1)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:42.507038Z",
     "start_time": "2019-12-29T04:20:41.476980Z"
    }
   },
   "outputs": [],
   "source": [
    "# scale the remaining features\n",
    "for attr in attributes:\n",
    "    X[attr] = scale(X[attr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-sample the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:42.626045Z",
     "start_time": "2019-12-29T04:20:42.511039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 1463, 1: 1463})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NateDogg\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# oversample the dataset to balance it, for improved prediction capability\n",
    "sm_res = SMOTE(random_state=43)\n",
    "X_sm, y_sm = sm_res.fit_sample(X, y)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_sm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:42.670048Z",
     "start_time": "2019-12-29T04:20:42.637046Z"
    }
   },
   "outputs": [],
   "source": [
    "# recombine the arrays, after oversampling, as DataFrames\n",
    "smX_df = pd.DataFrame(X_sm)\n",
    "smY_df = pd.DataFrame(y_sm)\n",
    "\n",
    "oversampled_df = pd.concat([smX_df, smY_df], axis=1)\n",
    "oversampled_df.columns = np.arange(0, oversampled_df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset - Train / Test / Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:42.779054Z",
     "start_time": "2019-12-29T04:20:42.676048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:    (1755, 479)\n",
      "VALIDATE: (585, 479)\n",
      "TEST:     (586, 479)\n",
      "-----------------------------------\n",
      "THE OVERSAMPLED DATASET, NOW SPLIT:\n"
     ]
    }
   ],
   "source": [
    "# establish the initial dataset split\n",
    "split_data = train_test_validate_split(oversampled_df)   # [train, validate, test]\n",
    "\n",
    "# re-assign the split results\n",
    "print('-----------------------------------')\n",
    "print('THE OVERSAMPLED DATASET, NOW SPLIT:')\n",
    "train_data = split_data[0]\n",
    "val_data = split_data[1]\n",
    "test_data = split_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:42.815056Z",
     "start_time": "2019-12-29T04:20:42.789055Z"
    }
   },
   "outputs": [],
   "source": [
    "# establish the features and target segmentations\n",
    "X_train = train_data[attributes]\n",
    "Y_train = train_data[target]\n",
    "\n",
    "X_test = test_data[attributes]\n",
    "Y_test = test_data[target]\n",
    "\n",
    "X_val = val_data[attributes]\n",
    "Y_val = val_data[target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T02:26:37.966723Z",
     "start_time": "2019-12-29T02:26:37.949722Z"
    }
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:46.110242Z",
     "start_time": "2019-12-29T04:20:43.619101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA\n",
      "Accuracy: 87.88%\n",
      "\n",
      "VALIDATION DATA\n",
      "Accuracy: 85.64%\n"
     ]
    }
   ],
   "source": [
    "# return the basic entropy decision tree\n",
    "clf_entropy = DecisionTreeClassifier(criterion='entropy').fit(X_train, Y_train)\n",
    "print('TEST DATA')\n",
    "Y_entropy_test_pred = clf_entropy.predict(X_test)\n",
    "print_scores_decision_tree(Y_test, Y_entropy_test_pred)\n",
    "\n",
    "print('\\nVALIDATION DATA')\n",
    "Y_entropy_val_pred = clf_entropy.predict(X_val)\n",
    "print_scores_decision_tree(Y_val, Y_entropy_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:46.166246Z",
     "start_time": "2019-12-29T04:20:46.143244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX - TEST - ENTROPY MODEL\n",
      "           Predicted PASS  Predicted FAIL\n",
      "True PASS             240              51\n",
      "True FAIL              20             275\n",
      "\n",
      "CONFUSION MATRIX - VALIDATION - ENTROPY MODEL\n",
      "           Predicted PASS  Predicted FAIL\n",
      "True PASS             248              59\n",
      "True FAIL              25             253\n"
     ]
    }
   ],
   "source": [
    "# return the confusion matrix\n",
    "print('CONFUSION MATRIX - TEST - ENTROPY MODEL')\n",
    "print(conf_matrix(Y_test, Y_entropy_test_pred, 'FAIL', 'PASS'))\n",
    "\n",
    "print('\\nCONFUSION MATRIX - VALIDATION - ENTROPY MODEL')\n",
    "print(conf_matrix(Y_val, Y_entropy_val_pred, 'FAIL', 'PASS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:46.194247Z",
     "start_time": "2019-12-29T04:20:46.172246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PASS-FAIL\n",
      "entropy: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# return the classifications of the binary states of the fitted models\n",
    "print('       PASS-FAIL')\n",
    "print('entropy: {}'.format(clf_entropy.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:46.391258Z",
     "start_time": "2019-12-29T04:20:46.363257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC TEST SCORES - PASS\n",
      "entropy: 0.8784728289358728\n",
      "\n",
      "AUC VALIDATION SCORES - PASS\n",
      "entropy: 0.8589447660112952\n"
     ]
    }
   ],
   "source": [
    "# predict the probabilities for each decision tree\n",
    "Y_entropy_test_pred_proba = clf_entropy.predict_proba(X_test)\n",
    "Y_entropy_val_pred_proba = clf_entropy.predict_proba(X_val)\n",
    "\n",
    "# compute the AUC scores\n",
    "print('AUC TEST SCORES - PASS')\n",
    "print('entropy: {}'.format(roc_auc_score(Y_test, Y_entropy_test_pred_proba[:,1])))\n",
    "\n",
    "print('\\nAUC VALIDATION SCORES - PASS')\n",
    "print('entropy: {}'.format(roc_auc_score(Y_val, Y_entropy_val_pred_proba[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision / Recall / F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:47.529317Z",
     "start_time": "2019-12-29T04:20:47.502316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTROPY MODEL - TEST DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87       291\n",
      "           1       0.84      0.93      0.89       295\n",
      "\n",
      "    accuracy                           0.88       586\n",
      "   macro avg       0.88      0.88      0.88       586\n",
      "weighted avg       0.88      0.88      0.88       586\n",
      "\n",
      "\n",
      "ENTROPY MODEL - VALIDATION DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86       307\n",
      "           1       0.81      0.91      0.86       278\n",
      "\n",
      "    accuracy                           0.86       585\n",
      "   macro avg       0.86      0.86      0.86       585\n",
      "weighted avg       0.86      0.86      0.86       585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# return the precision and recall results\n",
    "print('ENTROPY MODEL - TEST DATA')\n",
    "print(classification_report(Y_test, Y_entropy_test_pred))\n",
    "\n",
    "print('\\nENTROPY MODEL - VALIDATION DATA')\n",
    "print(classification_report(Y_val, Y_entropy_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GINI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:50.721487Z",
     "start_time": "2019-12-29T04:20:48.556363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA\n",
      "Accuracy: 86.86%\n",
      "\n",
      "VALIDATION DATA\n",
      "Accuracy: 87.69%\n"
     ]
    }
   ],
   "source": [
    "# return the basic gini decision tree\n",
    "clf_gini = DecisionTreeClassifier(criterion='gini').fit(X_train, Y_train)\n",
    "print('TEST DATA')\n",
    "Y_gini_test_pred = clf_gini.predict(X_test)\n",
    "print_scores_decision_tree(Y_test, Y_gini_test_pred)\n",
    "\n",
    "print('\\nVALIDATION DATA')\n",
    "Y_gini_val_pred = clf_gini.predict(X_val)\n",
    "print_scores_decision_tree(Y_val, Y_gini_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:50.773490Z",
     "start_time": "2019-12-29T04:20:50.726487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX- TEST - GINI MODEL\n",
      "           Predicted PASS  Predicted FAIL\n",
      "True PASS             240              51\n",
      "True FAIL              26             269\n",
      "\n",
      "CONFUSION MATRIX - VALIDATION - GINI MODEL\n",
      "           Predicted PASS  Predicted FAIL\n",
      "True PASS             254              53\n",
      "True FAIL              19             259\n"
     ]
    }
   ],
   "source": [
    "# return the confusion matrix\n",
    "print('CONFUSION MATRIX- TEST - GINI MODEL')\n",
    "print(conf_matrix(Y_test, Y_gini_test_pred, 'FAIL', 'PASS'))\n",
    "\n",
    "print('\\nCONFUSION MATRIX - VALIDATION - GINI MODEL')\n",
    "print(conf_matrix(Y_val, Y_gini_val_pred, 'FAIL', 'PASS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:51.096508Z",
     "start_time": "2019-12-29T04:20:51.083508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PASS-FAIL\n",
      "gini:    [0 1]\n"
     ]
    }
   ],
   "source": [
    "# return the classifications of the binary states of the fitted models\n",
    "print('       PASS-FAIL')\n",
    "print('gini:    {}'.format(clf_gini.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:51.760546Z",
     "start_time": "2019-12-29T04:20:51.725544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC TEST SCORES - PASS\n",
      "gini:    0.8683033374104491\n",
      "\n",
      "AUC VALIDATION SCORES - PASS\n",
      "gini:    0.8795081198884541\n"
     ]
    }
   ],
   "source": [
    "# predict the probabilities for each decision tree\n",
    "Y_gini_test_pred_proba = clf_gini.predict_proba(X_test)\n",
    "Y_gini_val_pred_proba = clf_gini.predict_proba(X_val)\n",
    "\n",
    "# compute the AUC scores\n",
    "print('AUC TEST SCORES - PASS')\n",
    "print('gini:    {}'.format(roc_auc_score(Y_test, Y_gini_test_pred_proba[:,1])))\n",
    "\n",
    "print('\\nAUC VALIDATION SCORES - PASS')\n",
    "print('gini:    {}'.format(roc_auc_score(Y_val, Y_gini_val_pred_proba[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision / Recall / F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:52.991612Z",
     "start_time": "2019-12-29T04:20:52.955610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINI MODEL - TEST DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86       291\n",
      "           1       0.84      0.91      0.87       295\n",
      "\n",
      "    accuracy                           0.87       586\n",
      "   macro avg       0.87      0.87      0.87       586\n",
      "weighted avg       0.87      0.87      0.87       586\n",
      "\n",
      "\n",
      "GINI MODEL - VALIDATION DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88       307\n",
      "           1       0.83      0.93      0.88       278\n",
      "\n",
      "    accuracy                           0.88       585\n",
      "   macro avg       0.88      0.88      0.88       585\n",
      "weighted avg       0.88      0.88      0.88       585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# return the precision and recall results\n",
    "print('GINI MODEL - TEST DATA')\n",
    "print(classification_report(Y_test, Y_gini_test_pred))\n",
    "\n",
    "print('\\nGINI MODEL - VALIDATION DATA')\n",
    "print(classification_report(Y_val, Y_gini_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:57.481840Z",
     "start_time": "2019-12-29T04:20:54.640680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.08570790e-04 9.14249129e-04 1.44156732e-03 2.78085876e-04\n",
      " 3.82219812e-04 0.00000000e+00 2.97408568e-05 8.97824968e-04\n",
      " 2.32316855e-03 4.31262533e-04 2.17794233e-03 2.14073965e-03\n",
      " 5.36350485e-04 2.02858743e-03 3.56287241e-04 9.59494834e-04\n",
      " 9.01241363e-04 1.35045391e-03 1.73827367e-04 3.77605233e-04\n",
      " 3.60885940e-03 2.98216997e-04 7.56403000e-04 3.64646171e-03\n",
      " 6.47201718e-04 7.60576088e-04 1.49145760e-03 9.16698038e-03\n",
      " 4.08284192e-04 1.28056877e-03 4.04563152e-03 3.09099506e-03\n",
      " 8.55866509e-03 1.25859334e-03 1.49490567e-03 1.20673280e-05\n",
      " 2.36371316e-03 1.17755610e-03 2.81774949e-04 1.97002087e-03\n",
      " 1.35593332e-03 0.00000000e+00 1.40545890e-03 0.00000000e+00\n",
      " 9.05644919e-04 3.34407790e-04 2.53573700e-03 1.97483696e-04\n",
      " 0.00000000e+00 1.37045438e-03 5.27868913e-04 1.29445619e-03\n",
      " 9.11358982e-04 8.56770211e-04 4.33342441e-04 1.29674141e-03\n",
      " 1.42884663e-03 3.77820083e-02 1.04732896e-04 1.10730483e-04\n",
      " 9.91248056e-04 1.49417349e-03 3.32664747e-03 3.11008060e-03\n",
      " 6.23427637e-04 1.80771005e-03 9.41602987e-04 0.00000000e+00\n",
      " 1.73497607e-03 5.56312550e-04 2.36849958e-02 1.94393826e-02\n",
      " 0.00000000e+00 2.02047098e-05 3.02360161e-03 2.53160761e-04\n",
      " 3.14454938e-04 1.75273554e-03 3.76438313e-04 1.28939131e-03\n",
      " 3.57264231e-04 1.46009632e-03 3.83296235e-04 5.39780231e-05\n",
      " 6.72612393e-04 7.82990632e-04 2.30232067e-06 7.59273089e-04\n",
      " 2.85038963e-03 2.24888941e-03 1.55364296e-03 4.45828928e-04\n",
      " 4.44987467e-03 1.38958548e-02 5.73959416e-04 2.57506407e-03\n",
      " 2.01788159e-03 1.38570851e-03 5.48339222e-03 3.17184795e-03\n",
      " 1.13146276e-02 5.08018609e-04 1.00434815e-03 0.00000000e+00\n",
      " 1.24512466e-03 8.64514135e-04 5.22127338e-03 1.32977748e-03\n",
      " 1.05684443e-03 4.72574951e-03 3.80609998e-04 0.00000000e+00\n",
      " 8.59681534e-04 2.26618651e-03 2.10377504e-03 1.78288231e-03\n",
      " 5.55908673e-04 6.82501942e-04 2.10826301e-02 8.46301926e-04\n",
      " 6.44463037e-03 2.07133293e-02 2.57855955e-03 2.62097462e-03\n",
      " 4.29949185e-04 0.00000000e+00 2.83639942e-03 1.48993736e-02\n",
      " 2.94486610e-03 1.32681584e-03 3.08705788e-03 3.83513106e-04\n",
      " 2.47304200e-03 9.73501920e-04 6.14609350e-03 0.00000000e+00\n",
      " 1.94429152e-03 1.46019944e-03 0.00000000e+00 2.77044152e-03\n",
      " 1.66242580e-03 1.55847442e-03 0.00000000e+00 4.74023126e-04\n",
      " 4.77635271e-04 7.21277272e-04 1.00634679e-03 4.98197859e-03\n",
      " 7.44749439e-04 6.26179065e-04 5.23105577e-03 1.73239268e-03\n",
      " 0.00000000e+00 3.59787475e-04 1.36809549e-03 4.91801343e-03\n",
      " 3.43982930e-04 4.91876542e-04 5.17733077e-04 9.37983649e-05\n",
      " 5.62815739e-04 7.03489858e-04 1.13374161e-03 2.69302067e-04\n",
      " 2.97349999e-04 2.93876434e-04 2.74317131e-04 3.82251858e-03\n",
      " 2.59232678e-03 4.48842206e-03 5.89677302e-03 3.73792126e-04\n",
      " 7.41075940e-04 6.39656786e-04 7.99411898e-04 8.32233660e-04\n",
      " 8.69840171e-04 4.79107641e-04 5.36393566e-04 2.72569955e-03\n",
      " 1.20469257e-03 2.83191262e-04 1.71157983e-03 3.34412691e-03\n",
      " 2.47526690e-03 1.28922797e-03 9.24429769e-03 1.76066562e-03\n",
      " 3.22374003e-03 1.63481860e-03 1.15503366e-03 1.49555012e-02\n",
      " 0.00000000e+00 3.14810415e-03 1.22337326e-03 0.00000000e+00\n",
      " 2.00404532e-03 1.05477262e-03 0.00000000e+00 3.90788972e-03\n",
      " 6.38263987e-04 2.16258313e-03 3.80812896e-04 2.16943937e-03\n",
      " 4.31435246e-04 8.16269329e-04 0.00000000e+00 1.69593936e-03\n",
      " 3.91703001e-04 5.84831544e-04 1.06345331e-03 3.84324198e-04\n",
      " 1.03687363e-03 7.37231316e-04 6.60974069e-04 2.75831417e-03\n",
      " 1.27898747e-03 7.91306846e-04 1.17467834e-04 1.12241925e-02\n",
      " 1.09219259e-04 0.00000000e+00 1.43317611e-03 7.16119412e-04\n",
      " 5.40775673e-04 8.90503835e-05 1.75927703e-03 7.25386926e-06\n",
      " 8.34390540e-04 2.01072337e-03 0.00000000e+00 2.11886875e-03\n",
      " 1.70742373e-03 1.79279612e-03 3.83281072e-05 1.49805574e-03\n",
      " 2.52377724e-04 2.95097372e-04 4.68410281e-03 7.03929871e-04\n",
      " 1.14192014e-03 8.92992986e-04 1.90680885e-03 2.30531796e-04\n",
      " 1.01812826e-03 3.53944285e-03 1.49335650e-02 6.23964787e-04\n",
      " 6.96223136e-04 8.64621659e-03 6.70122565e-04 0.00000000e+00\n",
      " 0.00000000e+00 9.60881444e-04 1.38074413e-03 5.36158672e-04\n",
      " 1.95433008e-03 5.24504811e-04 2.01054017e-04 1.67971481e-04\n",
      " 2.29251314e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 3.42563296e-04 1.26963599e-03 2.28502275e-03\n",
      " 4.63893545e-03 3.91207512e-03 3.26099419e-04 9.00061806e-04\n",
      " 2.67965282e-03 1.16250880e-03 1.14164659e-03 2.22652049e-03\n",
      " 5.18830206e-06 3.65975415e-04 1.39972789e-03 4.02601995e-04\n",
      " 6.81244177e-04 1.79271333e-03 3.36175328e-03 4.07620708e-04\n",
      " 1.65503340e-03 2.46239626e-03 2.08594934e-03 4.53418124e-04\n",
      " 3.30314664e-03 4.46142960e-04 1.22022698e-02 0.00000000e+00\n",
      " 4.33011838e-03 7.84781589e-04 1.50875012e-02 1.90141094e-02\n",
      " 0.00000000e+00 2.30645209e-03 0.00000000e+00 6.73108683e-04\n",
      " 3.69133565e-03 1.41405067e-03 1.08944105e-03 4.97250033e-04\n",
      " 2.61656613e-03 5.41556092e-04 4.79331607e-04 0.00000000e+00\n",
      " 1.75415268e-03 8.64594754e-04 7.33785519e-04 1.24048578e-03\n",
      " 4.14580558e-05 1.28113941e-03 1.84157026e-03 1.36995517e-03\n",
      " 9.45983493e-04 0.00000000e+00 7.01920149e-03 1.91032424e-03\n",
      " 4.30603577e-04 7.10572955e-04 3.85768283e-03 7.52926533e-04\n",
      " 0.00000000e+00 7.50398019e-04 0.00000000e+00 5.08950981e-03\n",
      " 6.09044041e-05 2.04974259e-03 2.08494563e-03 1.42716935e-03\n",
      " 7.34596318e-04 2.01083369e-03 1.08282517e-03 2.30469809e-04\n",
      " 4.42739096e-03 2.92066427e-04 2.24667341e-03 4.84196900e-04\n",
      " 3.20136350e-04 3.07670271e-03 1.71177546e-03 3.64697984e-04\n",
      " 1.39187698e-02 1.00357086e-03 5.46194239e-04 5.57060575e-04\n",
      " 5.12065335e-04 1.10643848e-02 5.64696302e-04 3.56839750e-04\n",
      " 4.63411163e-03 1.07720733e-03 1.87813739e-03 1.52199544e-03\n",
      " 3.69129708e-04 2.73185955e-03 7.07940675e-04 3.20972058e-04\n",
      " 5.73736853e-04 1.49450711e-03 1.28886290e-03 2.30436317e-04\n",
      " 5.34605832e-04 5.44662932e-04 1.29532203e-03 4.19849137e-03\n",
      " 1.69277321e-03 4.89028584e-03 6.54478944e-03 1.16263111e-03\n",
      " 1.30076618e-03 2.38629230e-03 9.66510344e-04 2.31796676e-03\n",
      " 1.95606059e-03 2.05921007e-04 6.56103281e-04 5.25631020e-04\n",
      " 2.86964505e-03 6.33134116e-04 3.19238299e-03 2.16873344e-03\n",
      " 1.76323687e-03 1.99920135e-03 5.45952494e-04 3.07352111e-03\n",
      " 1.43367690e-03 1.37221841e-03 1.05348949e-03 1.26471615e-02\n",
      " 0.00000000e+00 4.08479622e-03 1.20109776e-03 1.71049664e-03\n",
      " 1.02782583e-03 2.76203637e-04 1.97646131e-03 2.87553609e-02\n",
      " 1.05354962e-02 2.91988471e-04 8.73638785e-03 2.06608485e-04\n",
      " 4.48346394e-04 0.00000000e+00 1.11232884e-03 1.89874499e-05\n",
      " 4.26861570e-04 2.11810441e-03 4.30140805e-04 3.54668766e-04\n",
      " 3.82683741e-03 7.39249851e-03 6.22729976e-03 1.05080309e-03\n",
      " 1.64375724e-03 0.00000000e+00 9.82608666e-03 1.79330580e-04\n",
      " 1.69396036e-04 2.57753240e-03 1.41071415e-03 1.09451765e-03\n",
      " 1.39238194e-04 2.46711110e-03 7.87953274e-04 1.14120856e-03\n",
      " 3.96358148e-04 1.86804468e-03 1.39036397e-04 1.19678577e-03\n",
      " 2.62663670e-04 4.51386868e-04 2.23115332e-03 5.04962152e-06\n",
      " 4.92351585e-04 7.48020760e-04 5.11005347e-04 0.00000000e+00\n",
      " 1.80394764e-03 1.16270477e-03 0.00000000e+00 5.57335194e-04\n",
      " 9.14625762e-04 1.97873648e-04 1.46157328e-03 7.25684883e-03\n",
      " 2.23115979e-03 8.78377248e-03 4.26745212e-03 8.15855442e-03\n",
      " 6.83114309e-04 9.59903876e-04 7.05979054e-04 6.97635132e-04\n",
      " 8.66359870e-04 4.41481461e-05 4.48031801e-05 3.22305171e-04\n",
      " 5.81369964e-04 7.68527134e-04 7.00537416e-04 1.09567109e-03\n",
      " 1.31945468e-03 3.38810364e-04 2.23948293e-04 4.31405706e-03\n",
      " 5.39637629e-03 3.03174779e-04 1.43690624e-03 7.83142997e-04\n",
      " 9.31519105e-04 8.34262057e-04 1.62481713e-04 6.76242184e-05\n",
      " 4.58958291e-04 1.35505984e-03]\n"
     ]
    }
   ],
   "source": [
    "# employ basic hyperparameters to the RANDOM FOREST model\n",
    "nTrees = 100\n",
    "max_depth = 5\n",
    "min_node_size = 5\n",
    "verbose = 0\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=nTrees, max_depth=max_depth, random_state=0, verbose=verbose, min_samples_leaf=min_node_size)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:57.638849Z",
     "start_time": "2019-12-29T04:20:57.486841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "=============\n",
      "TEST DATASET\n",
      "93.17%\n",
      "\n",
      "VALIDATION DATASET\n",
      "92.48%\n"
     ]
    }
   ],
   "source": [
    "# Return the Random Forest Decision Tree accuracy scores\n",
    "print('RANDOM FOREST\\n=============')\n",
    "print('TEST DATASET')\n",
    "print_scores_ensemble_tree(clf, X_test, Y_test)\n",
    "\n",
    "print('\\nVALIDATION DATASET')\n",
    "print_scores_ensemble_tree(clf, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:57.791858Z",
     "start_time": "2019-12-29T04:20:57.648850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST - TEST - Confusion Matrix:\n",
      "           Predicted PASS  Predicted FAIL\n",
      "True PASS             261              30\n",
      "True FAIL              10             285\n",
      "\n",
      "RANDOM FOREST - VALIDATION - Confusion Matrix:\n",
      "           Predicted PASS  Predicted FAIL\n",
      "True PASS             276              31\n",
      "True FAIL              13             265\n"
     ]
    }
   ],
   "source": [
    "# return the confusion matrix for the RANDOM FOREST model\n",
    "Y_random_test_pred = clf.predict(X_test)\n",
    "print('RANDOM FOREST - TEST - Confusion Matrix:')\n",
    "print(conf_matrix(Y_test, Y_random_test_pred, 'FAIL', 'PASS'))\n",
    "\n",
    "Y_random_val_pred = clf.predict(X_val)\n",
    "print('\\nRANDOM FOREST - VALIDATION - Confusion Matrix:')\n",
    "print(conf_matrix(Y_val, Y_random_val_pred, 'FAIL', 'PASS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:57.973868Z",
     "start_time": "2019-12-29T04:20:57.810859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC TEST SCORES - PASS\n",
      "random forest:    0.9821655308987128\n",
      "\n",
      "AUC VALIDATION SCORES - PASS\n",
      "random forest:    0.9823893328334076\n"
     ]
    }
   ],
   "source": [
    "# predict the probabilities for each decision tree\n",
    "Y_random_test_pred_proba = clf.predict_proba(X_test)\n",
    "Y_random_val_pred_proba = clf.predict_proba(X_val)\n",
    "\n",
    "# compute the AUC scores\n",
    "print('AUC TEST SCORES - PASS')\n",
    "print('random forest:    {}'.format(roc_auc_score(Y_test, Y_random_test_pred_proba[:,1])))\n",
    "\n",
    "print('\\nAUC VALIDATION SCORES - PASS')\n",
    "print('random forest:    {}'.format(roc_auc_score(Y_val, Y_random_val_pred_proba[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision / Recall / F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:20:58.479897Z",
     "start_time": "2019-12-29T04:20:58.453896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST MODEL - TEST DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       291\n",
      "           1       0.90      0.97      0.93       295\n",
      "\n",
      "    accuracy                           0.93       586\n",
      "   macro avg       0.93      0.93      0.93       586\n",
      "weighted avg       0.93      0.93      0.93       586\n",
      "\n",
      "\n",
      "RANDOM FOREST MODEL - VALIDATION DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       307\n",
      "           1       0.90      0.95      0.92       278\n",
      "\n",
      "    accuracy                           0.92       585\n",
      "   macro avg       0.93      0.93      0.92       585\n",
      "weighted avg       0.93      0.92      0.92       585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# return the precision and recall results\n",
    "print('RANDOM FOREST MODEL - TEST DATA')\n",
    "print(classification_report(Y_test, Y_random_test_pred))\n",
    "\n",
    "print('\\nRANDOM FOREST MODEL - VALIDATION DATA')\n",
    "print(classification_report(Y_val, Y_random_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:22:11.141034Z",
     "start_time": "2019-12-29T04:20:59.499943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.20562718e-03 2.52433421e-04 1.29690206e-03 5.72149305e-04\n",
      " 1.38478147e-03 0.00000000e+00 6.06025673e-04 4.18964515e-06\n",
      " 2.50948931e-04 2.00192333e-05 9.53596450e-04 1.04994525e-04\n",
      " 6.96192910e-05 5.88688234e-04 4.24443171e-06 1.53490097e-03\n",
      " 1.20105280e-03 1.09891829e-02 1.41843398e-03 9.11843673e-04\n",
      " 3.44892583e-03 2.98382852e-04 1.33379851e-03 3.96259869e-04\n",
      " 1.03335755e-03 6.59950916e-04 4.18116517e-04 1.10785118e-02\n",
      " 4.50607742e-04 1.24140566e-04 1.01677491e-02 3.64356816e-03\n",
      " 2.41919725e-02 2.53350478e-03 2.33020535e-04 1.25232867e-04\n",
      " 2.43819930e-04 2.12880624e-04 1.05530516e-04 1.35330925e-03\n",
      " 4.83597534e-04 0.00000000e+00 1.35259697e-04 1.49241114e-04\n",
      " 2.05291243e-04 1.77944025e-04 5.92714493e-03 1.77850569e-03\n",
      " 0.00000000e+00 2.00555593e-03 5.17546469e-07 8.39724876e-03\n",
      " 0.00000000e+00 5.33637548e-03 5.38409414e-03 2.42392927e-04\n",
      " 8.55453012e-04 1.49449721e-01 7.94809185e-05 2.65284219e-04\n",
      " 5.68007195e-04 1.01019142e-05 4.89837634e-03 1.04559801e-02\n",
      " 4.00889799e-06 8.55341711e-03 1.08222834e-03 0.00000000e+00\n",
      " 1.25492108e-04 1.41289163e-03 1.40676085e-02 1.71820282e-02\n",
      " 0.00000000e+00 4.94564022e-05 1.15943611e-03 1.27698843e-04\n",
      " 7.72046944e-04 9.37618088e-04 4.39133215e-04 1.39395053e-03\n",
      " 4.08824650e-04 2.74597526e-04 3.67609708e-04 0.00000000e+00\n",
      " 2.83227595e-04 2.50330613e-04 1.92920643e-04 9.71388028e-05\n",
      " 4.52967228e-04 4.10620468e-03 1.07065473e-03 2.91343868e-05\n",
      " 1.08011019e-02 3.98791452e-02 1.58213609e-04 1.40683020e-04\n",
      " 1.80179349e-04 6.92916173e-03 4.77126464e-03 4.61600593e-03\n",
      " 1.76524818e-03 6.60611824e-04 0.00000000e+00 0.00000000e+00\n",
      " 1.13404514e-03 2.41011826e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.52986889e-03 4.03993800e-04 0.00000000e+00\n",
      " 7.47667586e-04 6.12064018e-04 4.29962942e-04 2.90198965e-04\n",
      " 1.34575496e-05 2.70219053e-03 5.50861430e-02 0.00000000e+00\n",
      " 2.35245137e-03 3.91056720e-04 3.89761435e-04 5.39574890e-04\n",
      " 5.40574367e-04 2.48114019e-03 1.00931232e-02 7.93827638e-03\n",
      " 7.74334662e-03 4.37495778e-04 6.54214330e-04 7.31154425e-05\n",
      " 4.72942030e-04 2.26627200e-04 1.53581199e-04 1.24987890e-04\n",
      " 1.30935972e-02 3.04860535e-04 3.15177796e-05 1.22962867e-03\n",
      " 5.72651118e-03 9.22840963e-05 0.00000000e+00 8.45943891e-04\n",
      " 1.01681478e-06 1.14125005e-03 0.00000000e+00 5.37952766e-04\n",
      " 0.00000000e+00 9.58949294e-05 2.12901700e-05 6.20858816e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 7.62691733e-05\n",
      " 1.20474201e-04 0.00000000e+00 1.80944251e-05 1.89178080e-05\n",
      " 0.00000000e+00 0.00000000e+00 8.98923809e-03 4.42700914e-05\n",
      " 1.83160131e-04 0.00000000e+00 2.57311329e-04 0.00000000e+00\n",
      " 2.40351694e-03 4.58343322e-05 1.12079381e-05 2.38825977e-03\n",
      " 0.00000000e+00 5.42283216e-04 7.27411147e-04 2.41486182e-03\n",
      " 3.45272757e-04 3.54374884e-04 3.07109509e-03 5.12022936e-04\n",
      " 5.31198800e-04 1.74216540e-04 3.47079385e-03 1.50823847e-03\n",
      " 9.61569873e-04 9.40821872e-05 1.76800696e-04 8.60256045e-03\n",
      " 5.18764431e-03 1.21282546e-04 1.55303203e-04 2.19504092e-03\n",
      " 0.00000000e+00 1.36453825e-04 3.99139878e-04 0.00000000e+00\n",
      " 1.33275816e-03 4.08074455e-05 3.00547444e-06 1.80694226e-03\n",
      " 6.50844315e-05 2.23976051e-04 2.18455644e-05 0.00000000e+00\n",
      " 1.50926647e-03 1.17446784e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 7.67659654e-04 0.00000000e+00 0.00000000e+00\n",
      " 2.64561651e-04 5.83942508e-03 9.03239017e-05 8.44667092e-04\n",
      " 2.91122952e-04 9.04980211e-06 4.91604837e-03 3.72682233e-04\n",
      " 5.93011364e-04 1.25605660e-04 5.95112994e-06 1.13309634e-06\n",
      " 0.00000000e+00 0.00000000e+00 1.98239338e-04 4.37613492e-04\n",
      " 1.47615020e-03 1.38254761e-04 0.00000000e+00 2.16029191e-03\n",
      " 4.07504375e-04 1.23217440e-03 1.50506852e-03 6.68366878e-05\n",
      " 6.64357145e-04 4.02045973e-04 4.49923309e-03 4.60109800e-03\n",
      " 3.17825598e-05 1.14318986e-03 0.00000000e+00 1.92542996e-05\n",
      " 5.52638840e-04 3.67042730e-04 5.72995191e-03 8.22212631e-05\n",
      " 3.70053789e-04 1.28754658e-03 1.28750973e-03 0.00000000e+00\n",
      " 1.48521393e-05 2.33432168e-03 1.58736199e-04 9.50602373e-06\n",
      " 4.19010715e-05 1.91785529e-06 0.00000000e+00 1.33558805e-04\n",
      " 3.57746615e-05 1.36686891e-02 2.77935764e-04 8.41474705e-05\n",
      " 6.14528185e-06 8.45196568e-04 2.33045988e-05 2.16420499e-03\n",
      " 1.42540521e-04 3.95387774e-03 1.78340075e-06 3.89561379e-06\n",
      " 2.72569801e-03 1.76948087e-04 5.24995366e-04 1.04054415e-04\n",
      " 3.01879490e-04 1.00843484e-03 2.61387030e-03 1.77459390e-05\n",
      " 4.55994045e-04 2.40405963e-04 3.20635770e-04 1.24081650e-04\n",
      " 8.25944985e-05 1.06674327e-04 1.11241964e-04 2.69512901e-03\n",
      " 7.23688219e-03 5.58615133e-04 2.27675346e-03 0.00000000e+00\n",
      " 1.33883062e-02 1.16259368e-03 1.61383882e-04 1.76971894e-04\n",
      " 0.00000000e+00 2.71226361e-03 0.00000000e+00 5.85646678e-05\n",
      " 5.96305314e-05 3.51106319e-05 8.50896906e-05 7.25354023e-05\n",
      " 3.57068645e-05 9.03017863e-04 3.74866589e-04 0.00000000e+00\n",
      " 2.09864231e-05 1.74241020e-04 1.07342518e-03 1.05527728e-03\n",
      " 3.67737851e-05 1.97018982e-03 7.08635374e-04 4.43405328e-05\n",
      " 2.16862170e-05 3.70103401e-04 0.00000000e+00 1.09416047e-02\n",
      " 6.96913081e-06 5.73858759e-05 1.51890406e-03 6.74320608e-04\n",
      " 0.00000000e+00 0.00000000e+00 5.14416295e-04 6.80367394e-03\n",
      " 2.43762817e-04 3.88044116e-03 3.43127277e-05 2.65024304e-05\n",
      " 5.60905403e-03 1.05948206e-05 0.00000000e+00 1.25453371e-04\n",
      " 1.76316136e-04 7.01993992e-05 1.34855727e-03 8.04465528e-05\n",
      " 1.04680137e-04 1.34339784e-03 9.03912842e-06 1.10738974e-04\n",
      " 3.90844445e-02 1.00247037e-03 9.33219004e-07 2.64791616e-03\n",
      " 1.16027170e-05 4.95298281e-03 1.24899020e-05 0.00000000e+00\n",
      " 1.40278907e-04 4.70125189e-06 4.78049915e-04 4.43912384e-04\n",
      " 0.00000000e+00 2.25007096e-03 2.60905391e-04 9.39161854e-06\n",
      " 0.00000000e+00 1.38385978e-04 7.03031482e-06 1.45230210e-06\n",
      " 2.96070995e-05 2.54150985e-03 8.87861143e-06 1.23324423e-04\n",
      " 8.27979789e-04 1.37981454e-02 1.49858336e-04 1.14304567e-03\n",
      " 0.00000000e+00 1.30465829e-05 3.14175481e-04 3.55949649e-05\n",
      " 0.00000000e+00 8.86732011e-04 4.75120137e-06 9.58292605e-04\n",
      " 5.30274869e-03 1.21749715e-04 6.63177822e-04 4.36631168e-04\n",
      " 3.51794363e-04 1.45135970e-05 3.98616777e-04 1.59481275e-03\n",
      " 5.14694859e-04 1.13525193e-04 9.57176343e-05 1.60468191e-02\n",
      " 0.00000000e+00 3.59080588e-05 2.95538399e-03 3.30738936e-04\n",
      " 1.09098565e-03 8.35071288e-04 6.99139015e-04 4.39756783e-02\n",
      " 1.06294711e-02 1.85617397e-04 1.50733645e-02 6.86553073e-03\n",
      " 1.72176568e-03 0.00000000e+00 4.62871496e-06 0.00000000e+00\n",
      " 4.88470277e-05 0.00000000e+00 3.42439683e-05 2.06985333e-04\n",
      " 1.52497349e-03 7.81994643e-03 3.29971532e-02 3.97343095e-04\n",
      " 1.34038575e-05 2.42142181e-05 4.13107283e-05 5.26009050e-04\n",
      " 0.00000000e+00 2.19776285e-04 3.21873069e-04 1.57346857e-04\n",
      " 0.00000000e+00 6.58024527e-04 1.50055701e-03 3.89209610e-04\n",
      " 6.84372158e-06 1.09098874e-03 0.00000000e+00 1.11960894e-05\n",
      " 2.20221567e-04 1.13709059e-03 7.23256643e-05 8.92852072e-05\n",
      " 9.38666133e-04 6.68677946e-05 0.00000000e+00 0.00000000e+00\n",
      " 1.38156904e-04 1.11136257e-05 1.32316860e-05 0.00000000e+00\n",
      " 9.78552986e-05 0.00000000e+00 7.36654308e-05 1.10226178e-02\n",
      " 8.87992539e-04 9.32275729e-05 2.80846169e-03 1.14892764e-03\n",
      " 0.00000000e+00 1.26632075e-04 7.84958287e-05 5.26850419e-04\n",
      " 9.21323428e-05 1.46224961e-03 2.18204013e-04 9.05916090e-04\n",
      " 2.31579682e-05 1.87681041e-03 1.50565123e-03 2.31772436e-04\n",
      " 5.14058522e-04 4.26537773e-04 1.54471032e-03 1.31139249e-04\n",
      " 0.00000000e+00 1.36766367e-06 3.27742427e-04 1.11238370e-03\n",
      " 2.10754820e-03 1.63458314e-03 1.60018701e-04 1.30251855e-03\n",
      " 1.29505715e-04 3.71939258e-03]\n"
     ]
    }
   ],
   "source": [
    "# employ basic hyperparameters to the GRADIENT DESCENT model\n",
    "nTrees = 100\n",
    "max_depth = 5\n",
    "min_node_size = 5\n",
    "verbose = 0\n",
    "learning_rate = 0.05\n",
    "\n",
    "gbm_clf = GradientBoostingClassifier(n_estimators=nTrees, loss='deviance', learning_rate=learning_rate, max_depth=max_depth, \\\n",
    "                                    min_samples_leaf=min_node_size)\n",
    "gbm_clf.fit(X_train, Y_train)\n",
    "print(gbm_clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:22:11.284042Z",
     "start_time": "2019-12-29T04:22:11.150034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT BOOST\n",
      "=============\n",
      "TEST DATASET\n",
      "96.93%\n",
      "\n",
      "VALIDATION DATASET\n",
      "96.75%\n"
     ]
    }
   ],
   "source": [
    "# Return the Random Forest Decision Tree accuracy scores\n",
    "print('GRADIENT BOOST\\n=============')\n",
    "print('TEST DATASET')\n",
    "print_scores_ensemble_tree(gbm_clf, X_test, Y_test)\n",
    "\n",
    "print('\\nVALIDATION DATASET')\n",
    "print_scores_ensemble_tree(gbm_clf, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:22:11.450051Z",
     "start_time": "2019-12-29T04:22:11.294042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT DESCENT BOOST Confusion Matrix:\n",
      "           Predicted PASS  Predicted FAIL\n",
      "True PASS             279              12\n",
      "True FAIL               6             289\n",
      "\n",
      "GRADIENT DESCENT BOOST Confusion Matrix:\n",
      "           Predicted PASS  Predicted FAIL\n",
      "True PASS             292              15\n",
      "True FAIL               4             274\n"
     ]
    }
   ],
   "source": [
    "# return the confusion matrix for the RANDOM FOREST model\n",
    "Y_gradDescent_test_pred = gbm_clf.predict(X_test)\n",
    "print('GRADIENT DESCENT BOOST Confusion Matrix:')\n",
    "print(conf_matrix(Y_test, Y_gradDescent_test_pred, 'FAIL', 'PASS'))\n",
    "\n",
    "Y_gradDescent_val_pred = gbm_clf.predict(X_val)\n",
    "print('\\nGRADIENT DESCENT BOOST Confusion Matrix:')\n",
    "print(conf_matrix(Y_val, Y_gradDescent_val_pred, 'FAIL', 'PASS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:22:11.558057Z",
     "start_time": "2019-12-29T04:22:11.460052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC TEST SCORES - PASS\n",
      "gradiant boost:    0.8683033374104491\n",
      "\n",
      "AUC VALIDATION SCORES - PASS\n",
      "gradiant boost:    0.8795081198884541\n"
     ]
    }
   ],
   "source": [
    "# predict the probabilities for each decision tree\n",
    "Y_gradDescent_test_pred_proba = clf_gini.predict_proba(X_test)\n",
    "Y_gradDescent_val_pred_proba = clf_gini.predict_proba(X_val)\n",
    "\n",
    "# compute the AUC scores\n",
    "print('AUC TEST SCORES - PASS')\n",
    "print('gradiant boost:    {}'.format(roc_auc_score(Y_test, Y_gradDescent_test_pred_proba[:,1])))\n",
    "\n",
    "print('\\nAUC VALIDATION SCORES - PASS')\n",
    "print('gradiant boost:    {}'.format(roc_auc_score(Y_val, Y_gradDescent_val_pred_proba[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision / Recall / F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:22:11.645062Z",
     "start_time": "2019-12-29T04:22:11.568058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT DESCENT BOOST MODEL - TEST DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       291\n",
      "           1       0.96      0.98      0.97       295\n",
      "\n",
      "    accuracy                           0.97       586\n",
      "   macro avg       0.97      0.97      0.97       586\n",
      "weighted avg       0.97      0.97      0.97       586\n",
      "\n",
      "\n",
      "GRADIENT DESCENT BOOST MODEL - VALIDATION DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       307\n",
      "           1       0.95      0.99      0.97       278\n",
      "\n",
      "    accuracy                           0.97       585\n",
      "   macro avg       0.97      0.97      0.97       585\n",
      "weighted avg       0.97      0.97      0.97       585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# return the precision and recall results\n",
    "print('GRADIENT DESCENT BOOST MODEL - TEST DATA')\n",
    "print(classification_report(Y_test, Y_gradDescent_test_pred))\n",
    "\n",
    "print('\\nGRADIENT DESCENT BOOST MODEL - VALIDATION DATA')\n",
    "print(classification_report(Y_val, Y_gradDescent_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:22:39.053097Z",
     "start_time": "2019-12-29T04:22:35.074871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC - TEST DATA\n",
      "accuracy: 98.12%\n",
      "\n",
      "SVC - VALIDATION DATA\n",
      "accuracy: 98.12%\n"
     ]
    }
   ],
   "source": [
    "# define the SVC estimator model, with prediction\n",
    "sv_class = svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='scale',\n",
    "                   coef0=0.0, shrinking=True, probability=False, tol=0.001,\n",
    "                   cache_size=200, class_weight=None, verbose=False, max_iter=-1,\n",
    "                   decision_function_shape='ovr', break_ties=False, random_state=None\n",
    "                  ).fit(X_train, Y_train)\n",
    "\n",
    "sv_class_test_pred = sv_class.predict(X_test)\n",
    "print(\"SVC - TEST DATA\")\n",
    "print('accuracy: {}%'.format(np.round(accuracy_score(sv_class_test_pred, Y_test)*100, 2)))\n",
    "\n",
    "sv_class_val_pred = sv_class.predict(X_val)\n",
    "print(\"\\nSVC - VALIDATION DATA\")\n",
    "print('accuracy: {}%'.format(np.round(accuracy_score(sv_class_val_pred, Y_val)*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:25:49.413082Z",
     "start_time": "2019-12-29T04:25:13.442032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: linear\n",
      "accuracy: 90.44%\n",
      "\n",
      "kernel: poly\n",
      "degree: 2\n",
      "accuracy: 97.27%\n",
      "\n",
      "kernel: poly\n",
      "degree: 3\n",
      "accuracy: 95.9%\n",
      "\n",
      "kernel: poly\n",
      "degree: 4\n",
      "accuracy: 94.88%\n",
      "\n",
      "kernel: poly\n",
      "degree: 5\n",
      "accuracy: 95.73%\n",
      "\n",
      "kernel: poly\n",
      "degree: 6\n",
      "accuracy: 52.9%\n",
      "\n",
      "kernel: rbf\n",
      "accuracy: 98.12%\n",
      "\n",
      "kernel: sigmoid\n",
      "accuracy: 78.5%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the SVC estimator model using various kernels, with prediction\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for kern in kernels:\n",
    "    if kern=='poly':   # the 'degree' value only effects the 'poly' kernel\n",
    "        for deg in np.arange(2,7):\n",
    "            sv_class = svm.SVC(C=1.0, kernel=kern, degree=deg, gamma='scale',\n",
    "                               coef0=0.0, shrinking=True, probability=False, tol=0.001,\n",
    "                               cache_size=200, class_weight=None, verbose=False, max_iter=-1,\n",
    "                               decision_function_shape='ovr', break_ties=False, random_state=None\n",
    "                              ).fit(X_train, Y_train)\n",
    "            sv_class_pred = sv_class.predict(X_test)\n",
    "            print('kernel: {}\\ndegree: {}'.format(kern, deg))\n",
    "            print('accuracy: {}%\\n'.format(np.round(accuracy_score(sv_class_pred, Y_test)*100, 2)))\n",
    "    else:\n",
    "        sv_class = svm.SVC(C=1.0, kernel=kern, degree=3, gamma='scale',\n",
    "                           coef0=0.0, shrinking=True, probability=False, tol=0.001,\n",
    "                           cache_size=200, class_weight=None, verbose=False, max_iter=-1,\n",
    "                           decision_function_shape='ovr', break_ties=False, random_state=None\n",
    "                           ).fit(X_train, Y_train)\n",
    "        sv_class_pred = sv_class.predict(X_test)\n",
    "        print('kernel: {}'.format(kern))\n",
    "        print('accuracy: {}%\\n'.format(np.round(accuracy_score(sv_class_pred, Y_test)*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T04:28:12.560257Z",
     "start_time": "2019-12-29T04:25:49.418082Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: linear\n",
      "Parameter: 1\n",
      "90.44%\n",
      "\n",
      "kernel: linear\n",
      "Parameter: 2\n",
      "90.44%\n",
      "\n",
      "kernel: linear\n",
      "Parameter: 3\n",
      "90.44%\n",
      "\n",
      "kernel: linear\n",
      "Parameter: 4\n",
      "90.44%\n",
      "\n",
      "kernel: linear\n",
      "Parameter: 5\n",
      "90.44%\n",
      "\n",
      "kernel: linear\n",
      "Parameter: 6\n",
      "90.44%\n",
      "\n",
      "kernel: linear\n",
      "Parameter: 7\n",
      "90.44%\n",
      "\n",
      "kernel: linear\n",
      "Parameter: 8\n",
      "90.44%\n",
      "\n",
      "kernel: linear\n",
      "Parameter: 9\n",
      "90.44%\n",
      "\n",
      "kernel: linear\n",
      "Parameter: 10\n",
      "90.44%\n",
      "\n",
      "kernel: poly\n",
      "Parameter: 1\n",
      "95.9%\n",
      "\n",
      "kernel: poly\n",
      "Parameter: 2\n",
      "97.44%\n",
      "\n",
      "kernel: poly\n",
      "Parameter: 3\n",
      "97.27%\n",
      "\n",
      "kernel: poly\n",
      "Parameter: 4\n",
      "97.1%\n",
      "\n",
      "kernel: poly\n",
      "Parameter: 5\n",
      "97.1%\n",
      "\n",
      "kernel: poly\n",
      "Parameter: 6\n",
      "96.93%\n",
      "\n",
      "kernel: poly\n",
      "Parameter: 7\n",
      "96.93%\n",
      "\n",
      "kernel: poly\n",
      "Parameter: 8\n",
      "96.93%\n",
      "\n",
      "kernel: poly\n",
      "Parameter: 9\n",
      "96.93%\n",
      "\n",
      "kernel: poly\n",
      "Parameter: 10\n",
      "97.1%\n",
      "\n",
      "kernel: rbf\n",
      "Parameter: 1\n",
      "98.12%\n",
      "\n",
      "kernel: rbf\n",
      "Parameter: 2\n",
      "98.81%\n",
      "\n",
      "kernel: rbf\n",
      "Parameter: 3\n",
      "98.81%\n",
      "\n",
      "kernel: rbf\n",
      "Parameter: 4\n",
      "98.81%\n",
      "\n",
      "kernel: rbf\n",
      "Parameter: 5\n",
      "98.81%\n",
      "\n",
      "kernel: rbf\n",
      "Parameter: 6\n",
      "98.81%\n",
      "\n",
      "kernel: rbf\n",
      "Parameter: 7\n",
      "98.81%\n",
      "\n",
      "kernel: rbf\n",
      "Parameter: 8\n",
      "98.81%\n",
      "\n",
      "kernel: rbf\n",
      "Parameter: 9\n",
      "98.81%\n",
      "\n",
      "kernel: rbf\n",
      "Parameter: 10\n",
      "98.81%\n",
      "\n",
      "kernel: sigmoid\n",
      "Parameter: 1\n",
      "78.5%\n",
      "\n",
      "kernel: sigmoid\n",
      "Parameter: 2\n",
      "78.67%\n",
      "\n",
      "kernel: sigmoid\n",
      "Parameter: 3\n",
      "79.52%\n",
      "\n",
      "kernel: sigmoid\n",
      "Parameter: 4\n",
      "77.13%\n",
      "\n",
      "kernel: sigmoid\n",
      "Parameter: 5\n",
      "77.65%\n",
      "\n",
      "kernel: sigmoid\n",
      "Parameter: 6\n",
      "77.3%\n",
      "\n",
      "kernel: sigmoid\n",
      "Parameter: 7\n",
      "76.28%\n",
      "\n",
      "kernel: sigmoid\n",
      "Parameter: 8\n",
      "76.11%\n",
      "\n",
      "kernel: sigmoid\n",
      "Parameter: 9\n",
      "76.28%\n",
      "\n",
      "kernel: sigmoid\n",
      "Parameter: 10\n",
      "76.28%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the SVC estimator model using various kernels, with prediction\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for kern in kernels:\n",
    "    for reg in np.arange(1,11):\n",
    "        sv_class = svm.SVC(C=reg, kernel=kern, degree=3, gamma='scale',\n",
    "                           coef0=0.0, shrinking=True, probability=False, tol=0.001,\n",
    "                           cache_size=200, class_weight=None, verbose=False, max_iter=-1,\n",
    "                           decision_function_shape='ovr', break_ties=False, random_state=None\n",
    "                           ).fit(X_train, Y_train)\n",
    "        sv_class_pred = sv_class.predict(X_test)\n",
    "        acc = accuracy_score(sv_class_pred, Y_test)\n",
    "\n",
    "        print('kernel: {}\\nParameter: {}'.format(kern, reg))\n",
    "        print('{}%\\n'.format(np.round(acc*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T17:50:25.881818Z",
     "start_time": "2019-12-29T16:39:28.116885Z"
    }
   },
   "outputs": [],
   "source": [
    "# establish the SVC\n",
    "sv_class = svm.SVC()\n",
    "# define the GridSearch parameters; based upon previous hyperparameter tuning\n",
    "grid_values = {'kernel': ('rbf', 'linear'),\n",
    "               'C': [0.001, 0.009, 0.01, 0.09, 1., 2., 3., 4., 5.],\n",
    "               'gamma': [1., 2., 3., 4., 5., 6., 7., 8., 9.]\n",
    "              }\n",
    "# return the estimator, then fit it to the data\n",
    "grid_clf_test_acc = GridSearchCV(sv_class, param_grid=grid_values, scoring='accuracy')\n",
    "grid_clf_test_acc.fit(X_train, Y_train)\n",
    "grid_clf_acc_test_pred = grid_clf_test_acc.predict(X_test)\n",
    "\n",
    "grid_clf_val_acc = GridSearchCV(sv_class, param_grid=grid_values, scoring='accuracy')\n",
    "grid_clf_val_acc.fit(X_train, Y_train)\n",
    "grid_clf_acc_val_pred = grid_clf_val_acc.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch - Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T17:58:54.717922Z",
     "start_time": "2019-12-29T17:58:54.698921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA\n",
      "=========\n",
      "Best score: 0.9247863247863247\n",
      "Best Kernel: linear\n",
      "Best C: 1.0\n",
      "Best Gamma: 1.0\n",
      "\n",
      "VALIDATION DATA\n",
      "===============\n",
      "Best score: 0.9247863247863247\n",
      "Best Kernel: linear\n",
      "Best C: 1.0\n",
      "Best Gamma: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('TEST DATA')\n",
    "print('=========')\n",
    "# View the accuracy score\n",
    "print('Best score:', grid_clf_test_acc.best_score_) \n",
    "# View the best parameters for the model found using grid search\n",
    "print('Best Kernel:', grid_clf_test_acc.best_estimator_.kernel)\n",
    "print('Best C:', grid_clf_test_acc.best_estimator_.C) \n",
    "print('Best Gamma:', grid_clf_test_acc.best_estimator_.gamma)\n",
    "\n",
    "\n",
    "print('\\nVALIDATION DATA')\n",
    "print('===============')\n",
    "# View the accuracy score\n",
    "print('Best score:', grid_clf_val_acc.best_score_) \n",
    "# View the best parameters for the model found using grid search\n",
    "print('Best Kernel:', grid_clf_val_acc.best_estimator_.kernel)\n",
    "print('Best C:', grid_clf_val_acc.best_estimator_.C) \n",
    "print('Best Gamma:', grid_clf_val_acc.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T18:07:23.395017Z",
     "start_time": "2019-12-29T18:07:19.786810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model (TEST):        linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       235\n",
      "           1       1.00      0.84      0.91       351\n",
      "\n",
      "    accuracy                           0.90       586\n",
      "   macro avg       0.90      0.92      0.90       586\n",
      "weighted avg       0.92      0.90      0.91       586\n",
      "\n",
      "\n",
      "Best Model (VALIDATION): linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       259\n",
      "           1       1.00      0.85      0.92       326\n",
      "\n",
      "    accuracy                           0.92       585\n",
      "   macro avg       0.92      0.93      0.92       585\n",
      "weighted avg       0.93      0.92      0.92       585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# establish the 'best' SVC derived from GridSearchCV\n",
    "cost = 1.0\n",
    "kern = 'linear'\n",
    "gam = 1.0\n",
    "sv_class = svm.SVC(C=cost, kernel=kern, gamma=gam).fit(X_train, Y_train)\n",
    "\n",
    "sv_class_test_pred = sv_class.predict(X_test)\n",
    "sv_class_val_pred = sv_class.predict(X_val)\n",
    "\n",
    "# return the 'precision', 'recall', and 'f-score' of the preceding 'best' model\n",
    "print('Best Model (TEST):        {}\\n{}'.format(kern, classification_report(sv_class_test_pred, Y_test)))\n",
    "print('\\nBest Model (VALIDATION): {}\\n{}'.format(kern, classification_report(sv_class_val_pred, Y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T18:04:47.667110Z",
     "start_time": "2019-12-29T18:04:47.648108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT DESCENT BOOST Confusion Matrix (TEST DATA):\n",
      "           Predicted PASS  Predicted FAIL\n",
      "True PASS             235              56\n",
      "True FAIL               0             295\n",
      "\n",
      "GRADIENT DESCENT BOOST Confusion Matrix (VALIDATION DATA):\n",
      "           Predicted PASS  Predicted FAIL\n",
      "True PASS             259              48\n",
      "True FAIL               0             278\n"
     ]
    }
   ],
   "source": [
    "# return the confusion matrix for the RANDOM FOREST model\n",
    "print('GRADIENT DESCENT BOOST Confusion Matrix (TEST DATA):')\n",
    "print(conf_matrix(Y_test, sv_class_test_pred, 'FAIL', 'PASS'))\n",
    "\n",
    "print('\\nGRADIENT DESCENT BOOST Confusion Matrix (VALIDATION DATA):')\n",
    "print(conf_matrix(Y_val, sv_class_val_pred, 'FAIL', 'PASS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultant from the target feature is binary, an SVR model would need to use a different, continuous, feature.\n",
    "\n",
    "Therefore, the SVR approach is not established here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Milestone-02 assignment is intended to exemplify the various machine learning model types employed for typical categorical constructs of a feature rich dataset, one that is based upon predicting product PASS / FAIL outcomes established via a manufacturing process of diaper products.\n",
    "\n",
    "The initial data wrangling and analysis was executed in the Milestone-01 assignmnet and in part is replicated at the onset of this notebook. The various modifications made to the incoming dataset are: 1) mergin the initially segregated attribute and target attribute DataFrames, 2) removing the mean-zero attributes from the DataFrame, 3) scaling of all features, and 4) for improved prediction outcomes, the DataFrame is over-sampled so as to balance the target attribute.\n",
    "\n",
    "For the primary work of this assignment the following model types are established: 1) both entropy and gini type decision trees, 2) the random forest and gradient descent boost ensemble decision trees, and 3) a support vector classifier model. Each of these model is assessed standard metrics for deeper understanding of performance and comparison.\n",
    "\n",
    "For our decision trees, the following outcomes were shown:  \n",
    "    \n",
    "   - ENTROPY DECISION TREE\n",
    "         + Test Data Accuracy          87.88%\n",
    "         + Validation Data Accuracy    85.64%\n",
    "      \n",
    "         + AUC Test Score-PASS         0.88\n",
    "         + AUC Validation Score-PASS   0.86\n",
    "    \n",
    "   - GINI DECISION TREE\n",
    "         + Test Data Accuracy          86.86%\n",
    "         + Validation Data Accuracy    87.69%\n",
    "      \n",
    "         + AUC Test Score-PASS         0.87\n",
    "         + AUC Validation Score-PASS   0.88\n",
    "\n",
    "The results shown here clearly indicate that either the ENTROPY or the GINI decision tree model are comparable for the underlying dataset. \n",
    "\n",
    "For the ensemble decision tree models, the same results were accomplsihed. Mainly we now have:\n",
    "   - RANDOM FOREST DECISION TREE\n",
    "         + Test Data Accuracy          93.17%\n",
    "         + Validation Data Accuracy    92.48%\n",
    "      \n",
    "         + AUC Test Score-PASS         0.98\n",
    "         + AUC Validation Score-PASS   0.98\n",
    "   - GRADIENT DESCENT BOOST DECISION TREE\n",
    "         + Test Data Accuracy          96.93%\n",
    "         + Validation Data Accuracy    96.75%\n",
    "      \n",
    "         + AUC Test Score-PASS         0.87\n",
    "         + AUC Validation Score-PASS   0.88\n",
    "\n",
    "From the results of the ensemble decision trees, it appears that the gradient descent boost model has a slight improvement in accuracy over the random forest decision tree, however, the AUC scores are slightly lower. For further understanding the confusion matrices can be further obseeved (shown in the preceding code).\n",
    "\n",
    "The last model employed, a support vector classifier (svc), was initially hand-tuned via a comparison of different kernels and regularization parameters. The best results achieved were as follows:\n",
    "   - TEST DATA ONLY\n",
    "         + kernel: linear\n",
    "         + accuracy: 90.44%\n",
    "    \n",
    "         + kernel: poly\n",
    "         + degree: 2\n",
    "         + accuracy: 97.27%\n",
    "    \n",
    "         + kernel: rbf\n",
    "         + accuracy: 98.12%\n",
    "    \n",
    "         + kernel: sigmoid\n",
    "         + accuracy: 78.5%\n",
    "\n",
    "   - Comparing these results against the basic SVC model of our dataset gives:\n",
    "         + TEST DATA\n",
    "         + accuracy: 98.12%\n",
    "    \n",
    "         + VALIDATION DATA\n",
    "         + accuracy: 98.12%\n",
    "\n",
    "Further hand-tuning of the SVC model and its regularization parameter returned the following as best results:\n",
    "   - TEST DATA ONLY\n",
    "         + kernel:   linear\n",
    "         + cost:     1\n",
    "         + accuracy: 90.44%\n",
    "         \n",
    "         + kernel:    poly\n",
    "         + cost:      2\n",
    "         + accuracy:  97.44%\n",
    "         \n",
    "         + kernel:    rbf\n",
    "         + cost:      2\n",
    "         + accuracy:  98.81%\n",
    "         \n",
    "         + kernel:    sigmoid\n",
    "         + cost:      3\n",
    "         + accuracy:  79.52%\n",
    "\n",
    "With these hand-tuned results, the GridSearchCV algorithm is applied, where only kernel `linear` and `rbf` were evaluated:\n",
    "   - GridSearch CV: TEST DATA\n",
    "         + Best score:   0.9247863247863247\n",
    "         + Best Kernel:  linear\n",
    "         + Best C:       1.0\n",
    "         + Best Gamma:   1.0\n",
    "   - GridSearch CV: VALIDATION DATA\n",
    "         + Best score:   0.9247863247863247\n",
    "         + Best Kernel:  linear\n",
    "         + Best C:       1.0\n",
    "         + Best Gamma:   1.0\n",
    "\n",
    "As seen here, the GridSearch model performs equally well on both the TEST and VALIDATION dataset, given the GridSearchCV optimized parameters. As before, the confusion matrix can further provide insight to how the model perfomred across the datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371.465px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
